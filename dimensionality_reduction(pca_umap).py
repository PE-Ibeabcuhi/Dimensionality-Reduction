# -*- coding: utf-8 -*-
"""Dimensionality Reduction(PCA/UMAP).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uzfz1qk6vmb9-RDazmAjWYmCIG7lcN8v

### **Introduction**

This notebook aims to identify countries or regions with similar weather conditions by analyzing monthly recorded data from April to September. By using Principal Component Analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP) for dimensionality reduction and visualization, we can uncover patterns and clusters within the data.

The visualizations produced by PCA and UMAP help reduce the complexity of the dataset, making it easier to identify regions with similar weather conditions based on multiple metrics. These insights can be valuable in various business applications, such as targeting markets with similar characteristics, optimizing supply chains, and tailoring marketing strategies to specific regional weather patterns.
"""

pip install umap-learn

# Importing necessary Libraries

# Computation libraries
import numpy as np
import pandas as pd

# Vizualization libraries
import plotly.graph_objs as go
import plotly.figure_factory as ff

# Preprocessing Libraries
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import umap

# Loading the dataset
dataset = pd.read_csv("/content/Avg_Temperatures.csv")
dataset.head()

"""### **Exploratory Data Analysis(EDA)**
For the purpose of this project, we would not go into detail on exploring the dataset. However, as a good practise, we will perform the basic EDA on the dataset.
"""

# Getting the full information of the dataset
dataset.info()

# Checking for null values
dataset.isna().sum()

# Confirming the total number of regions in the dataset
dataset['Regions'].nunique()
dataset['Regions'].unique()

# Getting the overall statistics of the dataset
dataset.describe()

"""#### ***Observation:***
The dataset contains non-null values, 93 entries which implies 93 regions, and 12 columns, of which 11 of the columns represent the monthly weatherr conditions from April to December, given in float datatype.

Moreso, from the overall statistics, we can tell the average weather condition for each months, as well as the max and minimum weather condition, amongst other statistics.

### **Preprocessing**
"""

# Dividing dataset into label and feature sets
X = dataset.drop(['Regions'], axis = 1) # Features
Y = dataset['Regions'] # Labels

# Getting the set of each sets
print(X.shape)
print(Y.shape)

# Normalizing numerical features so that each feature has mean 0 and variance 1
feature_scaler = StandardScaler()
X_scaled = feature_scaler.fit_transform(X)

"""### **Principal Component Analysis(PCA)**
PCA is a statistical technique used for dimensionality reduction, data visualization, and feature extraction. It transforms a large set of variables into a smaller one that still contains most of the information in the original set, allowing analyst easily visualize multidimensional datasets with large variables. It is also helpful in noise redcution,identifying patterns and correlations in the data, etc.

Read more about it [here](https://builtin.com/data-science/step-step-explanation-principal-component-analysis)
"""

# Applying PCA for initial dimensionality reduction
pca = PCA(n_components = 2)
pca.fit(X_scaled)
x_pca = pca.transform(X_scaled)
print("Variance explained by each of the n_components: ",pca.explained_variance_ratio_)
print("Total variance explained by the n_components: ",sum(pca.explained_variance_ratio_))

"""#### ***Observation***
The variance explained by each component indicates how much of the original data's variability is captured by that component. From the above we see that the first component captures 63% of the variance in the dataset, while the the second component captures 23% of the variance in the dataset, putting the overall variance captured in this dataset at 87.2%, implying that PCA is able to retain most of the important information in the dataset.

"""

# Creating a DataFrame for PCA results
pca_df = pd.DataFrame(data=x_pca, columns=['PC1', 'PC2'])
pca_df['Region'] = Y.values

pca_df.head()

"""##### ***Plotting UMAP Results***"""

# Visualizing PCA results
digits=list(dataset['Regions'])
data = [go.Scatter(x=x_pca[:,0], y=x_pca[:,1], mode='markers',
                    marker = dict(color=None, colorscale='Rainbow', opacity=0.5),
                                text=[f'digit: {a}' for a in digits],
                                hoverinfo='text')]

layout = go.Layout(title = 'PCA Dimensionality Reduction', width = 600, height = 600,
                    xaxis = dict(title='First Principal Component'),
                    yaxis = dict(title='Second Principal Component'))
fig = go.Figure(data=data, layout=layout)
fig.show()

"""#### ***Observations***
From the image above we can see clusters of regions with quite similar weather conditions.





### **Uniform Manifold Approximation and Projection (UMAP)**
UMAP is a nonlinear dimensionality reduction technique used for visualization and clustering of high-dimensional data. It is particularly effective at preserving both the local and global structure of the data, making it a popular choice for exploring datasets with even higher dimensions than what PCA can handle.

 Also, unlike PCA which is a linear technique and excels at capturing global variance and is good at preserving the large-scale structure of the data, UMAP is a nonlinear techinque, and is designed to preserve both local and global structures in the data.

 Read more about it [here](https://pair-code.github.io/understanding-umap/).
"""

# Applying UMAP for initial dimensionality reduction
u = umap.UMAP(n_components = 2, n_neighbors=15, min_dist=0.1)
x_umap = u.fit_transform(X_scaled)

# Creating a DataFrame for UMAP results
umap_df = pd.DataFrame(data=x_umap, columns=['UMAP1', 'UMAP2'])
umap_df['Region'] = Y.values

umap_df.head()

"""##### ***Plotting UMAP Results***"""

# Visualizing PCA results
data = [go.Scatter(x=x_umap[:,0], y=x_umap[:,1], mode='markers',
                    marker = dict(color=None, colorscale='Rainbow', opacity=0.5),
                                text=[f'digit: {a}' for a in digits],
                                hoverinfo='text')]

layout = go.Layout(title = 'UMAP Dimensionality Reduction', width = 600, height = 600,
                    xaxis = dict(title='First Dimension'),
                    yaxis = dict(title='Second Dimension'))
fig = go.Figure(data=data, layout=layout)
fig.show()

"""#### ***Observation***
From the chart above you can see even better clusters, showing regions with similar weather conditions.
"""